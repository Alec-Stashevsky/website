---
title: "Topology and Geometry Through GraphML"
author: "Alec Stashevsky"
date: 2022-11-26
categories: ["Mathematics", "GraphML", "Deep Learning"]
tags: ["Mathematics", "GraphML", "Deep Learning"]
bibliography: [topology-vs-geometry.bib]
link-citations: true
links:
image:
  preview_only: false
  focal_point: "Smart"
summary: Diving deeper into mathematics through my journey with industrial GraphML application.
---

<script src="{{< blogdown/postref >}}index_files/kePrint/kePrint.js"></script>
<link href="{{< blogdown/postref >}}index_files/lightable/lightable.css" rel="stylesheet" />


<style type="text/css">
table {
   overflow-x: hidden;
}

table > thead > tr > th {
    vertical-align: bottom;
    border-bottom: 2px solid rgb(232, 215, 195);
}

table > thead > tr > th, table > tbody > tr > th, table > tfoot > tr > th, table > thead > tr > td, table > tbody > tr > td, table > tfoot > tr > td {
    padding: 8px;
    line-height: 1.43;
    vertical-align: top;
    border-top: 1px solid rgb(232, 215, 195);
}

tbody > tr > td, table > tbody > tr > th {
    padding: 8px;
    line-height: 1.43;
    vertical-align: top;
    border-bottom: 1px solid rgb(232, 215, 195);
}


table > tfoot > tr > td {
    padding: 8px;
    line-height: 1.43;
    vertical-align: top;
    border-top: none;
}



table > tbody > tr:nth-child(2n+1) > td, table > tbody > tr:nth-child(2n+1) > th {
    background-color: rgb(255, 248, 227);
}

# Hover
table > tbody > tr:nth-child(2n+1):hover > td, table > tbody > tr:nth-child(2n+1):hover > th {
    background-color: rgb(232, 215, 195);
}

table > tbody > tr:hover > td, table > tbody > tr:hover > th {
    background-color: rgb(232, 215, 195);
}
</style>
<style type="text/css">
#references {
    text-indent: -2em;
    margin-left: 2em;
}
</style>
<blockquote>
<p>There is no royal road to geometry.</p>
<p><span style="float:right">— Euclid, <em>on account of Proclus of Athens</em></span></p>
</blockquote>
<p><br></p>
<p>This was Euclid’s response when asked by Ptolemy if no shorter road to geometry existed than through his <em>Elements. <link></em><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<p><br></p>
<p>For the past year I’ve been working with a team of folks at <a href="https://fetch.com/">Fetch</a> to develop and productionalize a machine learning based document understanding pipeline powering the core of the Fetch Rewards app. At Fetch, we reward our users for snapping pictures of their receipts in real-time, and we do it using this pipeline.</p>
<p>During this process, one of the things I’ve spent more time trying to do is understand unstructured data (such as images of receipts and the text which appears on them) in more elegant ways. This led me to a new and exciting place flourishing within the ML community: Graph Machine Learning (GraphML).</p>
<p>This post is about some of the things I’ve learned participating in the GraphML and Geometric Deep Learning communities. This post is also about some of the things I’ve had to forget in applying GraphML in large-scale industrial settings.</p>
<p><br></p>
<div id="graphs-are-all-around-us" class="section level2">
<h2>Graphs Are All Around Us</h2>
<p>When first learning about graphs, one usually encounters something like the following:</p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/basic%20graph-1.svg" width="672" /></p>
<p>A collection of <em>nodes</em> or <em>vertices</em> represented as dark green circles connected by a series of <em>edges</em> or <em>links</em> which indicate some pairwise relationship between two nodes.</p>
<p>Graphs are incredibly simple yet flexible data structures. Nodes and edges and can be added or removed as we please. We can also move, bend, and reorder the nodes without changing the underlying relational structure of the graph. That is, without changing the fundamental nature of the graph itself. For example, below I’ve moved some of the nodes of the graph around and switched node 3 and node 5.</p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/basic%20graph2-1.svg" width="672" /></p>
<p>Despite these modifications, the graph describes the same type of basic relational structure. We refer to this underlying structure as the graph’s <em>connectivity</em> or the <em>topology</em> of the graph. The graph’s topology is agnostic of where we position these nodes in space, or what we name individual nodes.</p>
<p>This also means graphs exist outside of Euclidean space where we have explicit notions of distance. I have no way of telling if node 3 is closer to node 4 or node 5 even though they appear father apart in the two examples above. Graphs like these, in their most basic form, do not model Euclid’s geometry. Perhaps there is a shorter road after all?</p>
<div id="what-happens-when-we-see-them" class="section level3">
<h3>What Happens When We See Them?</h3>
<p>One of the reasons GraphML is such an exciting space is just how abundant graphs are. A salient place to apply GraphML is in the modelling of molecules (link), where atoms are represented as nodes and their chemical bonds represented as edges. We also see social networks where user-profiles are nodes and their friendships, followers, or interactions form edges; financial networks with bank accounts as nodes and their transactions as edges of varying amounts; and even more recently, documents.</p>
<p>Where graphs can be seen, GraphML is there to teach machines how to make conclusions about them, and new unseen things we might later encounter. GraphML is being used to discover new therapeutic drugs (link), prevent the spread of misinformation in social networks (link to siraj) (and probably also help it too), identify bank fraud (capitalOne), and understand documents (link to graph paper).</p>
<p>As data scientists and machine learning researchers, our main goal is to make sense of the world around us. We do some of that by building models in and through which our understanding may grow. When we begin to see graph structure and its natural projections onto the world, we unlock a deeper and more organic connection by which to explain and infer phenomena. One of the ways graphs unlock this connection is through a blending of topological and geometric perspective.</p>
</div>
</div>
<div id="adding-geometry-to-graphs" class="section level2">
<h2>Adding Geometry to Graphs</h2>
<p>For machines to learn on data, be it graph-structured or not, we must represent the data in a way computers can digest. That is to say, we must encode the data into some <em>n</em>-dimensional (generally Euclidean) vector space, where individual data points can be represented as vectors within that space.</p>
<p>For example, consider GPS telemetry data used to monitor the movement of a newly released California Condor.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p><img src="condor_3d_map.jpeg" /></p>
<p>The data used to make that visualization might look something like this:</p>
<table style="NAborder-bottom: 0;">
<thead>
<tr>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; background-color: rgb(232, 215, 195); font-size: 1rem; padding: 0.15rem 0;" colspan="5">
<div style="">
Condor GPS Telemetry Data
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
Time
</th>
<th style="text-align:center;">
Condor
</th>
<th style="text-align:center;">
Latitude
</th>
<th style="text-align:center;">
Longitude
</th>
<th style="text-align:center;">
Altitude
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
0.12
</td>
<td style="text-align:center;">
190
</td>
<td style="text-align:center;">
36.4818
</td>
<td style="text-align:center;">
-121.1809
</td>
<td style="text-align:center;">
213
</td>
</tr>
<tr>
<td style="text-align:left;">
0.22
</td>
<td style="text-align:center;">
1031
</td>
<td style="text-align:center;">
36.4836
</td>
<td style="text-align:center;">
-121.1879
</td>
<td style="text-align:center;">
198
</td>
</tr>
<tr>
<td style="text-align:left;">
0.25
</td>
<td style="text-align:center;">
1031
</td>
<td style="text-align:center;">
36.4838
</td>
<td style="text-align:center;">
-121.1860
</td>
<td style="text-align:center;">
210
</td>
</tr>
<tr>
<td style="text-align:left;">
0.28
</td>
<td style="text-align:center;">
1031
</td>
<td style="text-align:center;">
36.4818
</td>
<td style="text-align:center;">
-121.1809
</td>
<td style="text-align:center;">
256
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; " colspan="100%">
<span style="font-weight: bold;">Notes:</span>
</td>
</tr>
<tr>
<td style="padding: 0; " colspan="100%">
<sup></sup> — The Time column is normalized from 0 to 1 which represent the start and end of the tracking period, respectively. <br>
— Each condor has an identification number. Condor 190 is <a href="https://www.ventanaws.org/condor190.html">Redwood Queen</a> and Condor 1031 is one of her offspring, <a href="https://www.ventanaws.org/condor1031.html">Iniko</a>. Redwood Queen and Iniko are real California Condors which are part of the free-ranging Central California flock! They have an amazing <a href="https://www.wildtones.com/birding-info/the-story-of-condor-chick-iniko">story</a>.
</td>
</tr>
</tfoot>
</table>
<p>To represent this data in some vector space, we need to encode it as numerical vectors. There are may different ways to do this. What is described below is certainly not the best way, but it keeps things simple. We perform the following transformations:</p>
<ol style="list-style-type: decimal">
<li>Represent the <em>Time</em> column as a scale from <em>0</em> to <em>1</em> where <em>0</em> is the first point in time we start tracking and 1 is the last</li>
<li>Number the <em>Condors</em> column from <em>1</em> to <em>n</em> where <em>n</em> is the number of condors we track in the data</li>
<li>Keep all other columns as is</li>
</ol>
<p>Now, our data looks something like this:</p>
<p>Each observation in the table can be represented as a column vector, like the one below. The elements of the vector now describe a part of a data point as a real number.</p>
<p><span class="math display">\[ \begin{bmatrix} Time \\ Condor \\ Latitude \\ Longitude \\ Altitude \end{bmatrix} \in \mathbb{R}^5  \]</span></p>
<p>This process introduces a <em>geometry</em> to our dataset</p>
<ul>
<li>embedding space. Now we can see how “far apart” nodes are by looking at their feature vectors.</li>
<li>talk about thinking about conventional relational data as graphs, how that induces a geometry in the graph.</li>
<li>images as graphs, molecules as graphs.</li>
</ul>
<!-- Bring this back at the end of post -->
</div>
<div id="teaching-machines-to-comprehend-documents" class="section level2">
<h2>Teaching Machines to Comprehend Documents</h2>
<p><em>Document Understanding</em> and <em>Document AI</em> are fields which use automated methods (specifically artificial intelligence in the case of the latter) to comprehend documents, such as scanned invoices, emails, legal filings(link?), and in our case: receipts. Document Understanding is a broad field which touches a wide range of sub fields within AI: Computer Vision (CV), Natural Language Processing (NLP), and even Graph Machine Learning (GraphML) (links?).</p>
<p>Industrial application of document AI is equally broad and includes:<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<ul>
<li>Identifying types of document (image classification)</li>
<li>Make document text searchable (optical character recognition)</li>
<li>Extracting and identifying important peices of text from a document (key information extraction)</li>
<li>Answering specific questions about documents (document question answering)</li>
</ul>
<p>Heaps of papers sitting unprocessed can now turn into rich harvests. Through Fetch, even your crumpled receipts are worth something!</p>
<ul>
<li><p>Talk about FormNet and use that to represent docuements as graphs.
<!-- End Move Block --></p></li>
<li><p>End with how you’ve learning about topology / geometry and larger understanding of the world</p></li>
</ul>
<div id="notes" class="section level3">
<h3>Notes</h3>
<ul>
<li>Features may be close together in euclidean space (cosine similarity etc)</li>
<li>May also have topological, or structural similarities that can also be leveraged</li>
<li>Graphs can let us learn from both the feature and their structure/connectivity/neighborhood</li>
</ul>
<p><br></p>
</div>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Morrow1992-MORPAC-8" class="csl-entry">
Morrow, Glenn R. 1992. <em>Proclus: A Commentary on the First Book of Euclid’s Elements</em>. Princeton University Press.
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><em>See</em> <span class="citation"><a href="#ref-Morrow1992-MORPAC-8" role="doc-biblioref">Morrow</a> (<a href="#ref-Morrow1992-MORPAC-8" role="doc-biblioref">1992</a>)</span>.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Picture provided by James Sheppard. <em>See</em> <a href="https://blogs.biomedcentral.com/bmcseriesblog/2015/09/02/behind-image-3d-home-range-california-condor/" class="uri">https://blogs.biomedcentral.com/bmcseriesblog/2015/09/02/behind-image-3d-home-range-california-condor/</a>.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p><em>See</em> <a href="https://huggingface.co/blog/document-ai" class="uri">https://huggingface.co/blog/document-ai</a>.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
